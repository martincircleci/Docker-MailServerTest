version: 2.1
orbs:
  aws-ecr: circleci/aws-ecr@7.3.0
  aws-cli: circleci/aws-cli@2.0.6
  pulumi: pulumi/pulumi@2.0.0
  slack: circleci/slack@4.6.1
  git-shallow-clone: guitarrapc/git-shallow-clone@2.4.0
  coveralls: coveralls/coveralls@1.0.6
  buildevents: honeycombio/buildevents@0.5.0

# This is called a CircleCI alias:
only_run_on_main: &only_run_on_main
  filters:
    branches:
      only: main

commands:
  install_packages:
    parameters:
      path:
        type: string
        default: .
      cache_version:
        type: string
        default: 'v11'
      cache_suffix:
        type: string
        default: ''
    steps:
      - restore_cache:
          keys:
            # not using a fallback cache to prevent unbounded growth of the cache as new packages are installed
            - << parameters.cache_version >>-deps-<< parameters.path >>-<< parameters.cache_suffix >>-{{ checksum "package-lock.json" }}
      - run:
          name: 'Disable husky'
          command: npm set-script prepare ""
      - when:
          condition:
            equal: [<< parameters.path >>, .]
          steps:
            - run:
                name: 'Installing all packages'
                command: npm ci --no-audit --no-fund --prefer-offline
      - when:
          condition:
            equal: [<< parameters.path >>, root]
          steps:
            - run:
                name: 'Installing root workspace packages'
                command: npm ci --workspaces=false --no-audit --no-fund --prefer-offline
      - when:
          condition:
            and:
              - not:
                  equal: [<< parameters.path >>, .]
              - not:
                  equal: [<< parameters.path >>, root]
          steps:
            - run:
                name: 'Installing << parameters.path >> workspace packages'
                command: npm ci --workspace=<<parameters.path>> --no-audit --no-fund --prefer-offline

      - save_cache:
          key: << parameters.cache_version >>-deps-<< parameters.path >>-<< parameters.cache_suffix >>-{{ checksum "package-lock.json" }}
          paths:
            - ~/.npm

  setup_test_env:
    steps:
      - run:
          name: 'Setup custom environment variables'
          # This is how we tell our tests they don't need to start a database container
          command: |
            echo "export USE_EXISTING_POSTGRES=1" >> $BASH_ENV
            echo "export USE_EXISTING_REDIS=1" >> $BASH_ENV
            echo "export NODE_ENV=test" >> $BASH_ENV

  notify_slack_on_failure:
    steps:
      - slack/notify:
          event: fail
          branch_pattern: main
          template: basic_fail_1
          mentions: '@channel'
  generate_code:
    steps:
      - run:
          name: 'Generate code'
          command: npm run --workspaces --if-present codegen

jobs:
  setup_honeycomb_build_events:
    docker:
      - image: cimg/node:16.13.2
    resource_class: small
    steps:
      - buildevents/start_trace
  watch_honeycomb_build_events:
    docker:
      - image: cimg/node:16.13.2
    resource_class: small
    steps:
      - when:
          condition:
            equal: [main, << pipeline.git.branch >>]
          steps:
            - buildevents/watch_build_and_finish:
                timeout: 30
      - when:
          condition:
            not:
              equal: [main, << pipeline.git.branch >>]
          steps:
            - buildevents/watch_build_and_finish:
                timeout: 15
  code_format:
    docker:
      - image: cimg/node:16.13.2
        environment:
          NODE_OPTIONS: --max_old_space_size=1536
          # use a standard port for running tests
          DB_PORT: 5432
    resource_class: small
    steps:
      - buildevents/with_job_span:
          steps:
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages:
                path: root
            - run:
                name: Prettier
                command: |
                  npx prettier --check .
      - notify_slack_on_failure

  lint_api:
    docker:
      - image: cimg/node:16.13.1
        environment:
          NODE_OPTIONS: --max_old_space_size=4096
    resource_class: medium
    steps:
      - buildevents/with_job_span:
          steps:
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages:
                path: packages/api
            - run:
                command: |
                  npm run compile --workspace=packages/api
            - run:
                name: API circular dependency check
                command: |
                  npm run --workspace=packages/api circular-deps-check
            - run:
                name: Lint api
                command: |
                  npm run --workspace=packages/api lint:ci
      - notify_slack_on_failure
  lint_web_app:
    docker:
      - image: cimg/node:16.13.1
        environment:
          NODE_OPTIONS: --max_old_space_size=4096
    resource_class: medium
    steps:
      - buildevents/with_job_span:
          steps:
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages:
                path: packages/web_app
            # perform type checking
            - run:
                command: |
                  npm run compile --workspace=packages/web_app
            - run:
                name: Web app circular dependency check
                command: |
                  npm run --workspace=packages/web_app circular-deps-check
            - run:
                name: Lint web app
                command: |
                  npm run --workspace=packages/web_app lint:ci
      - notify_slack_on_failure
  api_test:
    docker:
      - image: cimg/node:16.13.2
        environment:
          # we can't give the full 2gb of memory to node since we're also running the db
          NODE_OPTIONS: --max_old_space_size=1700
          # use a standard port for running tests
          DB_PORT: 5432
      - image: cimg/postgres:13.5
        environment:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: example
          POSTGRES_DB: postgres
      - image: cimg/redis:6.2.6
    resource_class: small
    parallelism: 8
    steps:
      - buildevents/with_job_span:
          steps:
            - setup_test_env
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages:
                path: packages/api
            - generate_code
            - run:
                name: Run API tests
                command: |
                  cd packages/api
                  mkdir -p reports
                  TEST=$(circleci tests glob "src/**/__tests__/**/*.test.ts" | circleci tests split --split-by=timings)
                  echo running tests $TEST
                  npm test -- --logHeapUsage --runInBand --reporters=default --reporters=jest-junit --testTimeout=20000 $TEST
                environment:
                  JEST_JUNIT_OUTPUT_DIR: reports
                  JEST_JUNIT_ADD_FILE_ATTRIBUTE: 'true'
        # coverage is currently causing api tests to grind to halt...
        # - coveralls/upload:
        #     parallel: true
        #     flag_name: API Tests
        #     path_to_lcov: './packages/api/coverage/lcov.info'
      - store_test_results:
          path: packages/api/reports
      - store_artifacts:
          path: packages/api/reports
      - notify_slack_on_failure

  lib_test:
    docker:
      - image: cimg/node:16.13.2
        environment:
          NODE_OPTIONS: --max_old_space_size=4096
    resource_class: medium
    steps:
      - buildevents/with_job_span:
          steps:
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages:
                path: packages/common_types
            - run:
                name: Run Library tests
                command: |
                  cd packages/common_types
                  mkdir -p reports
                  TEST=$(circleci tests glob "src/**/__tests__/**/*test.ts" | circleci tests split --split-by=timings)
                  echo running tests $TEST
                  npm test -- --runInBand --reporters=default --reporters=jest-junit --testTimeout=20000 --coverage $TEST
                environment:
                  JEST_JUNIT_OUTPUT_DIR: reports
                  JEST_JUNIT_ADD_FILE_ATTRIBUTE: 'true'
            - coveralls/upload:
                parallel: true
                path_to_lcov: './packages/common_types/coverage/lcov.info'
                flag_name: Common Types Tests
                verbose: true
      - store_test_results:
          path: packages/common_types/reports
      - store_artifacts:
          path: packages/common_types/reports
      - notify_slack_on_failure

  web_test:
    docker:
      - image: cimg/node:16.13.2
        environment:
          NODE_OPTIONS: --max_old_space_size=4000
    resource_class: medium
    steps:
      - buildevents/with_job_span:
          steps:
            - setup_test_env
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages:
                path: packages/web_app
            - run:
                name: Run Web App tests
                command: |
                  cd packages/web_app
                  mkdir -p reports
                  npm test -- --runInBand --reporters=default --reporters=jest-junit --testTimeout=20000 --coverage
                environment:
                  JEST_JUNIT_OUTPUT_DIR: reports
                  JEST_JUNIT_ADD_FILE_ATTRIBUTE: 'true'
            - coveralls/upload:
                parallel: true
                flag_name: Web App Tests
                path_to_lcov: './packages/web_app/coverage/lcov.info'
                verbose: true
      - store_test_results:
          path: packages/web_app/reports
      - store_artifacts:
          path: packages/web_app/reports
      - notify_slack_on_failure

  upload_coverage:
    docker:
      - image: cimg/node:16.13.2
    steps:
      - coveralls/upload:
          parallel_finished: true
          verbose: true

  storybook:
    docker:
      - image: cimg/node:16.13.2
    resource_class: medium+
    steps:
      - buildevents/with_job_span:
          steps:
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - install_packages
            - run:
                name: Build Storybook
                working_directory: packages/web_app/
                command: npm run storybook:build -- --quiet
            - store_artifacts:
                path: packages/web_app/storybook-static
            - run:
                name: Publish Storybook
                command: |
                  npx -w packages/devex ts-node -T src/cmd/main publish-storybook \
                    --github-app-key "${GITHUB_APP_KEY}" \
                    --build-number ${CIRCLE_BUILD_NUM} \
                    --circle-token ${CIRCLE_TOKEN} \
                    --git-sha ${CIRCLE_SHA1}

  bundle_stats:
    docker:
      - image: cimg/node:16.13.2
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout_advanced:
          clone_options: '--depth 3'
      - install_packages:
          path: packages/web_app
      - run:
          name: Bundle App
          working_directory: packages/web_app/
          command: npm run bundle:standalone -- --json dist/bundle_stats.json
          environment:
            WEBPACK_MODE: production

      - run:
          name: Report to RelativeCI
          working_directory: packages/web_app
          command: npx relative-ci-agent

  e2e_test:
    docker:
      - image: mcr.microsoft.com/playwright:v1.16.1
        environment:
          # use a standard port for running tests
          DB_PORT: 5432
          NODE_ENV: test
      - image: cimg/postgres@sha256:31987291d47f0bdf3ca5954c9be6bb42c421e3e417cc6d1de1ea667da4a34273
        environment:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: example
          POSTGRES_DB: postgres
      - image: roribio16/alpine-sqs:latest
      - image: circleci/redis:6.2.6-alpine
    resource_class: large
    steps:
      - buildevents/with_job_span:
          steps:
            - setup_test_env
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - run:
                name: Update certificates
                command: |
                  # Workaround for: https://github.com/nodesource/distributions/issues/1266
                  mv /etc/apt/sources.list.d/nodesource.list /etc/apt/sources.list.d/nodesource.list.disabled
                  apt-get update
                  apt-get install -y ca-certificates libgnutls30
                  mv /etc/apt/sources.list.d/nodesource.list.disabled /etc/apt/sources.list.d/nodesource.list
            - run:
                name: Install node
                command: |
                  curl -fsSL https://deb.nodesource.com/setup_16.x | bash -
                  apt-get install -y nodejs
            - install_packages:
                cache_suffix: e2e
            - generate_code
            - run:
                name: Install Doppler CLI to current directory
                command: |
                  apt-get install -y apt-transport-https gnupg
                  curl -sLf --retry 3 --tlsv1.2 --proto "=https" 'https://packages.doppler.com/public/cli/gpg.DE2A7741A397C129.key' | apt-key add -
                  echo "deb https://packages.doppler.com/public/cli/deb/debian any-version main" | tee /etc/apt/sources.list.d/doppler-cli.list
                  apt-get update && apt-get install doppler
            - run:
                name: Install additional dependencies
                command: |
                  apt install -y postgresql-client awscli
                  curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash
                  apt-get install git-lfs=3.0.1
            - run:
                name: Setup DB
                command: |
                  npm run --workspace=packages/api pretest
            - run:
                name: Start web server
                background: true
                command: |
                  cd packages/web_app
                  export NODE_ENV=development
                  npm run dev
            - run:
                name: Seed test data
                command: |
                  cd packages/api
                  git lfs pull
                  npx ts-node -T src/cmd/dumpling.ts --input=../e2e-tests/data/test_seed.gz --addSuperUser=true import
                  npx knex migrate:latest --cwd ./src/data/global/  --knexfile Knexfile.ts
            # This is disabled until we can push https://github.com/common-room/sparta/pull/3990
            # to prod and run projections.  Until we do that, consistency checks will fail.
            # - run:
            # name: Run consistency checker
            # command: |
            # cd packages/api
            # npx ts-node -T ./src/cmd/checkConsistency.ts check
            - run:
                name: Create test users
                command: |
                  cd packages/api
                  npx ts-node -T src/cmd/admin.ts createSU --suEmail test-superuser@commonroom.io
                  npx ts-node -T src/cmd/admin.ts setCommunityRole --memberEmail test-superuser@commonroom.io --communityId 251 --communityRoleName owner
            - run:
                name: Install browsers
                command: |
                  cd packages/e2e-tests/
                  npm run browsers
            - run:
                name: Create SQS queues
                command: |
                  export AWS_SECRET_ACCESS_KEY="test"
                  export AWS_ACCESS_KEY_ID="test"
                  export AWS_REGION=us-west-2
                  aws --region us-west-2 --endpoint-url http://localhost:9324 sqs create-queue --queue-name account_projection_0_hot
                  aws --region us-west-2 --endpoint-url http://localhost:9324 sqs create-queue --queue-name account_projection_1_warm
                  aws --region us-west-2 --endpoint-url http://localhost:9324 sqs create-queue --queue-name account_projection_2_warm
                  aws --region us-west-2 --endpoint-url http://localhost:9324 sqs create-queue --queue-name refresh_accounts_twitter
                  aws --region us-west-2 --endpoint-url http://localhost:9324 sqs create-queue --queue-name refresh_accounts_gitHub
            - run:
                name: Start API server
                background: true
                command: |
                  cd packages/api
                  export LOG_LEVEL=4
                  export CLEARBIT_API_KEY=test
                  export PDL_API_KEY=test
                  export RAMPED_UP_API_KEY=test
                  export SG_PRIMARY=test
                  export SECURE_COOKIES=0
                  export COOKIE_DOMAIN=localhost
                  export GITHUB_EVENT_SECRET=secret
                  export USE_MOCK_STATSIG_SERVER=true
                  export AWS_SECRET_ACCESS_KEY="test"
                  export AWS_ACCESS_KEY_ID="test"
                  export AWS_REGION=us-west-2
                  export PROJECTION_QUEUE_ENDPOINT_HOT=http://localhost:9324/queue/account_projection_0_hot
                  export PROJECTION_QUEUE_ENDPOINT_WARM=http://localhost:9324/queue/account_projection_0_warm
                  export PROJECTION_QUEUE_ENDPOINT_COLD=http://localhost:9324/queue/account_projection_0_cold
                  export REFRESH_TWITTER_ACCOUNT_ENDPOINT_HOT=http://localhost:9324/queue/refresh_accounts_twitter
                  export REFRESH_TWITTER_ACCOUNT_ENDPOINT_WARM=http://localhost:9324/queue/refresh_accounts_twitter
                  export REFRESH_TWITTER_ACCOUNT_ENDPOINT_COLD=http://localhost:9324/queue/refresh_accounts_twitter
                  export REFRESH_GITHUB_ACCOUNT_ENDPOINT_HOT=http://localhost:9324/queue/refresh_accounts_gitHub
                  export REFRESH_GITHUB_ACCOUNT_ENDPOINT_WARM=http://localhost:9324/queue/refresh_accounts_gitHub
                  export REFRESH_GITHUB_ACCOUNT_ENDPOINT_COLD=http://localhost:9324/queue/refresh_accounts_gitHub
                  export REDIS_HOST=127.0.0.1
                  export PROMETHEUS_SCRAPE_PORT=9466
                  export ENABLE_MIX_RANK_PROFILE_LOOKUP=false
                  export STREAMING_SERVICE=redis
                  npm run precompile
                  npm run start
            - run:
                name: Wait for API server
                command: npx wait-on --delay=5000 tcp:localhost:3001
            - run:
                name: Wait for web server
                command: npx wait-on --interval=1000 --delay=5000 http-get://localhost:3000
            - run:
                name: Run E2E tests
                command: |
                  cd packages/e2e-tests/
                  mkdir -p reports
                  doppler run --command "npm test"
                environment:
                  FOLIO_JUNIT_OUTPUT_NAME: reports/e2e/results.xml
      - store_artifacts:
          path: packages/e2e-tests/test-results
      - store_test_results:
          path: packages/e2e-tests/reports
      - notify_slack_on_failure

  # This sets the sha for the given pulumi project/stack and runs "pulumi up"
  pulumi_up:
    docker:
      - image: cimg/node:16.13.2
    resource_class: small
    parameters:
      project:
        description: The name of the Project Package we're running
        type: string
      stack:
        description: The stack to run against
        type: string
      working_directory:
        description: The root-relative path to the pulumi project directory
        type: string
      sentry_project:
        description: The name of the Sentry project for this deployment
        type: string
      sentry_environment:
        description: The name of the Sentry environment being deployed to
        type: string
      github_deployment_environment:
        type: string
        default: ''
      prevent_backwards_history:
        description: Prevents going backwards in git history. Only use this if deployedSha is exported from your stack
        type: boolean
        default: false

    steps:
      - buildevents/with_job_span:
          steps:
            - checkout
            - pulumi/login
            - when:
                condition:
                  equal: [<< parameters.prevent_backwards_history >>, true]
                steps:
                  - run:
                      name: Checking that we're not going backwards in git history
                      # is ancestor exits 0 if true and 1 if false
                      # we want the currently deployed sha to be an ancestor of the incoming
                      command: |
                        deployedSha=`pulumi stack --cwd << parameters.working_directory >> --stack << parameters.stack >> output deployedSha`
                        git merge-base --is-ancestor $deployedSha $CIRCLE_SHA1
            - install_packages:
                path: << parameters.working_directory >>
            # not worth caching installation of such a tiny workspace
            - run:
                name: Install devex packages
                command: npm install --workspace=packages/devex
            - run:
                name: Queue until ready
                command: |
                  npx -w packages/devex ts-node -T src/cmd/main queue-circleci \
                  --circle-token=${CIRCLECI_API_KEY} \
                  --build-number=${CIRCLE_BUILD_NUM} \
                  --job-name=${CIRCLE_JOB}

            - run:
                name: Set the SHA that should be pushed
                command: |
                  pulumi config set --plaintext common-room:sha $CIRCLE_SHA1 \
                    --cwd << parameters.working_directory >> \
                    --stack << parameters.stack >>
            - run:
                name: Preview what is about to happen
                command: |
                  pulumi preview --non-interactive --diff --cwd << parameters.working_directory >> --stack << parameters.stack >> --refresh

            - when:
                condition: << parameters.github_deployment_environment >>
                steps:
                  - run:
                      name: Create an in-progress github deployment
                      command: |
                        npx -w packages/devex ts-node -T src/cmd/main deployments \
                        --environment << parameters.github_deployment_environment >> \
                        --github-app-key "${GITHUB_APP_KEY}" \
                        --git-sha ${CIRCLE_SHA1} \
                        --state in_progress \
                        --job-url ${CIRCLE_BUILD_URL}

            - run:
                name: Update Pulumi Stack
                command: |
                  pulumi update --yes --stack << parameters.stack >> --cwd << parameters.working_directory >> --skip-preview --refresh
                no_output_timeout: 30m

            - when:
                condition: << parameters.github_deployment_environment >>
                steps:
                  - run:
                      name: Mark the github deployment as a success
                      command: |
                        npx -w packages/devex ts-node -T src/cmd/main deployments \
                        --environment << parameters.github_deployment_environment >> \
                        --github-app-key "${GITHUB_APP_KEY}" \
                        --git-sha ${CIRCLE_SHA1} \
                        --state success \
                        --job-url ${CIRCLE_BUILD_URL}

            - run:
                name: Create release and notify Sentry of deploy
                command: |
                  if [[ ! -z "<< parameters.sentry_project >>" ]]; then
                    curl -sL https://sentry.io/get-cli/ | bash
                    export SENTRY_RELEASE=${CIRCLE_SHA1}
                    export SENTRY_ORG=common-room
                    sentry-cli releases new -p << parameters.sentry_project >> $SENTRY_RELEASE
                    sentry-cli releases set-commits $SENTRY_RELEASE --auto
                    sentry-cli releases finalize $SENTRY_RELEASE
                    sentry-cli releases deploys $SENTRY_RELEASE new -e << parameters.sentry_environment >>
                  fi

            - run:
                name: Mark the github deployment as a failure
                command: |
                  if [[ ! -z "<< parameters.github_deployment_environment >>" ]]; then
                  npx -w packages/devex ts-node -T src/cmd/main deployments \
                    --environment << parameters.github_deployment_environment >> \
                    --github-app-key "${GITHUB_APP_KEY}" \
                    --git-sha ${CIRCLE_SHA1} \
                    --state failure \
                    --job-url ${CIRCLE_BUILD_URL}
                  fi
                when: on_fail

      - notify_slack_on_failure

  # This builds and publishes the static assets for the app.commonroom.io/dev sites to S3
  build_app_and_publish:
    docker:
      - image: cimg/node:16.13.2
    resource_class: medium+
    parameters:
      api_domain:
        type: string
      app_domain:
        type: string
      bucket_name:
        type: string

    steps:
      - aws-cli/setup
      - git-shallow-clone/checkout_advanced:
          clone_options: '--depth 3'
      - install_packages:
          path: packages/web_app
      - run:
          name: Build app
          command: |
            cd packages/web_app
            APP_DOMAIN="<< parameters.app_domain >>" \
              VERSION=${CIRCLE_SHA1} \
              PUBLIC_PATH=/commit/${CIRCLE_SHA1}/ \
              SENTRY_RELEASE=${CIRCLE_SHA1} \
              npm run bundle:standalone
          environment:
            # There are more settings in the environment that come from the context
            # build by the "cicd" pulumi project, such as REACT_APP_AUTH0_DOMAIN
            # and REACT_APP_AUTH0_CLIENT_ID
            GRAPHQL_URI: https://<< parameters.api_domain >>/graphql
            ADMIN_GRAPHQL_URI: https://<< parameters.api_domain >>/system
            GRAPHQL_SUBSCRIPTIONS_URI: wss://<< parameters.api_domain >>/graphql
            API_BASE_URI: https://<< parameters.api_domain >>
            AUTH0_API_IDENTIFIER: https://verify-login # needs to match from server
            FULL_STORY_DEV_MODE: 'off'
            FULL_STORY_ORG_ID: ZTBCV
            WEBPACK_MODE: production
      - run:
          name: Publish to S3 Bucket
          command: |
            cd packages/web_app
            aws s3 sync \
              --metadata="Commit=${CIRCLE_SHA1}" \
              "dist/standalone" \
              "s3://<< parameters.bucket_name >>/commit/${CIRCLE_SHA1}"
            aws s3 cp \
              --metadata="Commit=${CIRCLE_SHA1}" \
              --metadata-directive REPLACE --cache-control max-age=0 --content-type text/html \
              "s3://<< parameters.bucket_name >>/commit/${CIRCLE_SHA1}/index.html" \
              "s3://<< parameters.bucket_name >>/commit/${CIRCLE_SHA1}/index.html"

  # wrapper around aws-ecr/build-and-push-image orb to get access to shallow checkouts for much faster clones
  build_docker_and_push:
    executor: ubuntu
    resource_class: medium
    parameters:
      repo:
        description: Name of an Amazon ECR repository
        type: string
      tag:
        description: A comma-separated string containing docker image tags to build and push (default = latest)
        type: string
      dockerfile:
        description: Name of dockerfile to use. Defaults to Dockerfile.
        type: string
        default: 'Dockerfile'
      path:
        description: Path to the directory containing your Dockerfile and build context.
        type: string
      extra-build-args:
        description: |
          Extra flags to pass to docker build. For examples, see https://docs.docker.com/engine/reference/commandline/build
        type: string
        default: ''
    steps:
      - buildevents/with_job_span:
          steps:
            - git-shallow-clone/checkout_advanced:
                clone_options: '--depth 3'
            - aws-ecr/build-and-push-image:
                repo: << parameters.repo >>
                tag: << parameters.tag >>
                dockerfile: << parameters.dockerfile >>
                path: << parameters.path >>
                aws-access-key-id: AWS_API_ACCESS_KEY_ID
                aws-secret-access-key: AWS_API_SECRET_ACCESS_KEY
                region: AWS_DEFAULT_REGION
                checkout: false
                extra-build-args: << parameters.extra-build-args >>

workflows:
  build_test_deploy:
    jobs:
      - setup_honeycomb_build_events
      - watch_honeycomb_build_events:
          context: honeycomb
          requires:
            - setup_honeycomb_build_events
      - code_format:
          context:
            - honeycomb
            - slack-secrets
          requires:
            - setup_honeycomb_build_events
      - lint_api:
          context:
            - honeycomb
            - slack-secrets
          requires:
            - setup_honeycomb_build_events
      - lint_web_app:
          context:
            - honeycomb
            - slack-secrets
          requires:
            - setup_honeycomb_build_events
      - api_test:
          context:
            - honeycomb
            - slack-secrets
            - coveralls
          requires:
            - setup_honeycomb_build_events
      - lib_test:
          context:
            - honeycomb
            - slack-secrets
            - coveralls
          requires:
            - setup_honeycomb_build_events
      - web_test:
          context:
            - honeycomb
            - slack-secrets
            - coveralls
          requires:
            - setup_honeycomb_build_events
      - e2e_test:
          context:
            - honeycomb
            - slack-secrets
            - e2e-tests
          requires:
            - setup_honeycomb_build_events
      - upload_coverage:
          context:
            - honeycomb
            - coveralls
          requires:
            - lib_test
            - web_test
            - setup_honeycomb_build_events
      - storybook:
          context:
            - honeycomb
            - dev/storybook
          requires:
            - setup_honeycomb_build_events
      # Disabling until: 1) We decide to pay for this, 2) We replace it whit our own report
      # - bundle_stats:
      #     context:
      #       - relativeci
      - build_docker_and_push:
          <<: *only_run_on_main
          requires:
            - setup_honeycomb_build_events
          name: api_ecr_dev_push
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'main-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context:
            - honeycomb
            - ecr_push/dev
          dockerfile: ./docker/Dockerfile.api
          path: ./
          extra-build-args: '--build-arg VERSION=${CIRCLE_SHA1}'

      - api_monitoring_dev_hold:
          <<: *only_run_on_main
          type: approval

      - build_docker_and_push:
          <<: *only_run_on_main
          name: api_ecr_dev_otel_scraper_push
          requires:
            - api_monitoring_dev_hold
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'otel-scraper-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context: ecr_push/dev
          dockerfile: ./Dockerfile.otel-scraper
          path: ./docker

      - build_docker_and_push:
          <<: *only_run_on_main
          name: api_ecr_dev_fluentbit_push
          requires:
            - api_monitoring_dev_hold
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'fluentbit-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context: ecr_push/dev
          dockerfile: ./Dockerfile.fluentbit
          path: ./docker

      - build_docker_and_push:
          <<: *only_run_on_main
          name: api_ecr_dev_aws_otel_push
          requires:
            - api_monitoring_dev_hold
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'aws-otel-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context: ecr_push/dev
          dockerfile: ./Dockerfile.aws-otel
          path: ./docker

      - build_docker_and_push:
          <<: *only_run_on_main
          requires:
            - setup_honeycomb_build_events
          name: api_ecr_dev_worker_push
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'worker-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context:
            - honeycomb
            - ecr_push/dev
          dockerfile: ./docker/Dockerfile.worker
          path: ./
          extra-build-args: '--build-arg VERSION=${CIRCLE_SHA1}'

      - build_app_and_publish:
          <<: *only_run_on_main
          requires:
            - setup_honeycomb_build_events
          name: app_dev_s3_publish
          context:
            - honeycomb
            - app_pulumi_up/dev
          api_domain: api.commonroom.builders
          app_domain: app.commonroom.builders
          bucket_name: app.commonroom.builders

      - pulumi_up:
          <<: *only_run_on_main
          name: pulumi_dev_up_api
          requires:
            - api_ecr_dev_push
            - api_ecr_dev_worker_push
            - api_test
            - lib_test
            - web_test
            - e2e_test
            - lint_api
          context:
            # This context is created by the 'cicd' pulumi project and holds the
            # secrets/settings that we need to run 'pulumi up', which updates the
            # task definition in ECS to use the new sha
            - api_pulumi_up/dev
            - slack-secrets
            - devops-gh-app-private-key
            - honeycomb
          project: api_infra
          stack: common-room/dev
          working_directory: infra/api_infra
          sentry_project: api
          sentry_environment: dev
          github_deployment_environment: api.commonroom.builders
          prevent_backwards_history: true

      - pulumi_up:
          <<: *only_run_on_main
          name: pulumi_dev_up_app
          requires:
            - app_dev_s3_publish
            # Don't update the frontend until the backend has been pushed
            - api_ecr_dev_push
            - lint_web_app
            - pulumi_dev_up_api
          context:
            - app_pulumi_up/dev
            - slack-secrets
            - devops-gh-app-private-key
            - honeycomb
          project: app_infra
          stack: common-room/dev
          working_directory: infra/app_infra
          sentry_project: ui
          sentry_environment: dev
          github_deployment_environment: app.commonroom.builders

      # See comments in the previous build-and-push
      - build_docker_and_push:
          <<: *only_run_on_main
          requires:
            - setup_honeycomb_build_events
          name: api_ecr_prod_push
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'main-${CIRCLE_SHA1}'
          context:
            - honeycomb
            - ecr_push/prod
          dockerfile: ./docker/Dockerfile.api
          path: ./
          extra-build-args: '--build-arg VERSION=${CIRCLE_SHA1}'

      - api_monitoring_prod_hold:
          <<: *only_run_on_main
          type: approval

      - build_docker_and_push:
          <<: *only_run_on_main
          name: api_ecr_prod_otel_scraper_push
          requires:
            - api_monitoring_prod_hold
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'otel-scraper-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context: ecr_push/prod
          dockerfile: ./Dockerfile.otel-scraper
          path: ./docker

      - build_docker_and_push:
          <<: *only_run_on_main
          name: api_ecr_prod_fluentbit_push
          requires:
            - api_monitoring_prod_hold
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'fluentbit-${CIRCLE_SHA1}'
          context: ecr_push/prod
          dockerfile: ./Dockerfile.fluentbit
          path: ./docker

      - build_docker_and_push:
          <<: *only_run_on_main
          name: api_ecr_prod_aws_otel_push
          requires:
            - api_monitoring_prod_hold
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'aws-otel-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context: ecr_push/prod
          dockerfile: ./Dockerfile.aws-otel
          path: ./docker

      - build_docker_and_push:
          <<: *only_run_on_main
          requires:
            - setup_honeycomb_build_events
          name: api_ecr_prod_worker_push
          repo: '${AWS_RESOURCE_NAME_PREFIX}'
          tag: 'worker-${CIRCLE_SHA1}'
          # This context is created by the 'cicd' pulumi project and holds the
          # secrets/settings that we need to login to AWS and push this image
          context:
            - ecr_push/prod
            - honeycomb
          dockerfile: ./docker/Dockerfile.worker
          path: ./
          extra-build-args: '--build-arg VERSION=${CIRCLE_SHA1}'

      # We publish everything we build to S3 to decrease the latency after we decide
      # to push it.  This has no effect on the world until "pulumi up" runs and changes
      # what the CDN is serving.
      - build_app_and_publish:
          requires:
            - setup_honeycomb_build_events
          <<: *only_run_on_main
          name: app_prod_s3_publish
          context:
            - honeycomb
            - app_pulumi_up/prod
          api_domain: api.commonroom.io
          app_domain: app.commonroom.io
          bucket_name: app.commonroom.io

      - prod_api_hold:
          <<: *only_run_on_main
          type: approval
          requires:
            - api_ecr_prod_push
            - api_ecr_prod_worker_push
      - prod_ui_hold:
          <<: *only_run_on_main
          type: approval
          requires:
            - app_prod_s3_publish
            - pulumi_prod_up_api

      # See comments in the previous pulumi_up
      - pulumi_up:
          <<: *only_run_on_main
          name: pulumi_prod_up_api
          requires:
            - prod_api_hold
          context:
            - api_pulumi_up/prod
            - slack-secrets
            - devops-gh-app-private-key
          project: api_infra
          stack: common-room/prod
          working_directory: infra/api_infra
          sentry_project: api
          sentry_environment: prod
          github_deployment_environment: api.commonroom.io
          prevent_backwards_history: true

      - pulumi_up:
          <<: *only_run_on_main
          name: pulumi_prod_up_app
          requires:
            - prod_ui_hold
          context:
            - app_pulumi_up/prod
            - slack-secrets
            - devops-gh-app-private-key
          project: app_infra
          stack: common-room/prod
          working_directory: infra/app_infra
          sentry_project: ui
          sentry_environment: prod
          github_deployment_environment: app.commonroom.io

      - prod_stage_ui_hold:
          <<: *only_run_on_main
          type: approval
          requires:
            - app_prod_s3_publish
            - pulumi_prod_up_api

      - pulumi_up:
          <<: *only_run_on_main
          name: pulumi_prod_stage_up_app
          requires:
            - prod_stage_ui_hold
          context:
            - app_pulumi_up/prod
            - slack-secrets
            - devops-gh-app-private-key
          project: app_infra
          stack: common-room/prod-stage
          working_directory: infra/app_infra
          sentry_project: ui
          sentry_environment: prod
          github_deployment_environment: stage.commonroom.io

executors:
  ubuntu:
    machine:
      image: ubuntu-2004:202111-01
      # Our images are pretty small with few layers so we don't get a lot of benefit from layer caching
      docker_layer_caching: false
    environment:
      DOCKER_BUILDKIT: '1'
      BUILDKIT_PROGRESS: 'plain'
